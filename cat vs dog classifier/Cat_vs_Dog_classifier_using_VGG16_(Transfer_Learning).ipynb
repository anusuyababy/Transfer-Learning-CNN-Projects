{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Cat vs Dog classifier using VGG16 (Transfer Learning) ",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cxxonZfx_qNe"
      },
      "source": [
        "# TRANSFER LEARNING USING RESNET 50"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2GiibeY-_vg9"
      },
      "source": [
        "# import the libraries as shown below\r\n",
        "from tensorflow.keras.models import Sequential\r\n",
        "from tensorflow.keras.layers import Input, Lambda, Dense, Flatten\r\n",
        "from tensorflow.keras.models import Model\r\n",
        "from tensorflow.keras.applications.vgg16 import VGG16\r\n",
        "from tensorflow.keras.applications.vgg16 import preprocess_input\r\n",
        "from tensorflow.keras.preprocessing import image\r\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator,load_img\r\n",
        "import numpy as np\r\n",
        "from glob import glob\r\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 194,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CUUWJbNm_vj0"
      },
      "source": [
        "# re-size all the images to this\r\n",
        "IMAGE_SIZE = [224, 224]\r\n",
        "\r\n",
        "train_path = '/content/train'\r\n",
        "valid_path = '/content/test'"
      ],
      "execution_count": 195,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "77n36DqU_vnu"
      },
      "source": [
        "# Import the resnet 50 library as shown below and add preprocessing layer to the front of Resnet\r\n",
        "# Here we will be using imagenet weights\r\n",
        "\r\n",
        "vgg16 = VGG16(input_shape=IMAGE_SIZE + [3], weights='imagenet', include_top=False)"
      ],
      "execution_count": 196,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ddw_A-04_vqS"
      },
      "source": [
        "# don't train existing weights\r\n",
        "for layer in vgg16.layers:\r\n",
        "    layer.trainable = False"
      ],
      "execution_count": 197,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0VsoQbCD_vvE"
      },
      "source": [
        "# useful for getting number of output classes\r\n",
        "folders = glob('/content/train/*')"
      ],
      "execution_count": 198,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kep17cNQ_vxO"
      },
      "source": [
        "# output layers\r\n",
        "x = Flatten()(vgg16.output)"
      ],
      "execution_count": 199,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0qIKQYi4_v05"
      },
      "source": [
        "prediction = Dense(len(folders), activation='softmax')(x)\r\n",
        "# create a model object\r\n",
        "model = Model(inputs=vgg16.input, outputs=prediction)"
      ],
      "execution_count": 200,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MSu4w3R5_v4i",
        "outputId": "79689237-7415-420b-f07b-cb32114c9632"
      },
      "source": [
        "# view the structure of the model\r\n",
        "model.summary()"
      ],
      "execution_count": 201,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_12\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_13 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
            "_________________________________________________________________\n",
            "flatten_12 (Flatten)         (None, 25088)             0         \n",
            "_________________________________________________________________\n",
            "dense_12 (Dense)             (None, 2)                 50178     \n",
            "=================================================================\n",
            "Total params: 14,764,866\n",
            "Trainable params: 50,178\n",
            "Non-trainable params: 14,714,688\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s4sNqAO2BemK"
      },
      "source": [
        "model.compile(\r\n",
        "  loss='binary_crossentropy',\r\n",
        "  optimizer='adam',\r\n",
        "  metrics=['accuracy']\r\n",
        ")"
      ],
      "execution_count": 202,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R8-4rkXNBepA"
      },
      "source": [
        "# Use the Image Data Generator to import the images from the dataset\r\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\r\n",
        "\r\n",
        "train_data = ImageDataGenerator(rescale = 1./255,\r\n",
        "                                   shear_range = 0.2,\r\n",
        "                                   zoom_range = 0.2,\r\n",
        "                                   horizontal_flip = True)\r\n",
        "\r\n",
        "test_data = ImageDataGenerator(rescale = 1./255)"
      ],
      "execution_count": 203,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jp1l5sKlBet2",
        "outputId": "be920ed2-f082-4f06-f51c-0126f9289a01"
      },
      "source": [
        "# Make sure to provide the same target size as initialied for the image size\r\n",
        "training_set = train_data.flow_from_directory('/content/train',\r\n",
        "                                                 target_size = (224, 224),\r\n",
        "                                                 batch_size = 32,\r\n",
        "                                                 class_mode = 'categorical')"
      ],
      "execution_count": 204,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 20 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RD_hJ6T5BewS",
        "outputId": "dcfdefbb-6a62-420c-9631-397058147326"
      },
      "source": [
        "test_set = test_data.flow_from_directory('/content/test',\r\n",
        "                                            target_size = (224, 224),\r\n",
        "                                            batch_size = 32,\r\n",
        "                                            class_mode = 'categorical')"
      ],
      "execution_count": 205,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 4 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dspn-_SUBe0M",
        "outputId": "717b8975-68f9-40e9-8a73-d9788e523ab6"
      },
      "source": [
        "# fit the model and run the cell\r\n",
        "r = model.fit_generator(\r\n",
        "  training_set,\r\n",
        "  validation_data=test_set,\r\n",
        "  epochs=50,\r\n",
        "  steps_per_epoch=len(training_set),\r\n",
        "  validation_steps=len(test_set)\r\n",
        ")"
      ],
      "execution_count": 206,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.8883 - accuracy: 0.5000 - val_loss: 0.9730 - val_accuracy: 0.5000\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 446ms/step - loss: 0.8562 - accuracy: 0.5000 - val_loss: 0.8737 - val_accuracy: 0.5000\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 394ms/step - loss: 0.7478 - accuracy: 0.7500 - val_loss: 0.6982 - val_accuracy: 0.7500\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 383ms/step - loss: 0.5102 - accuracy: 0.8500 - val_loss: 0.7667 - val_accuracy: 0.7500\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 380ms/step - loss: 0.3708 - accuracy: 0.9500 - val_loss: 0.9009 - val_accuracy: 0.7500\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 390ms/step - loss: 0.3900 - accuracy: 0.9500 - val_loss: 0.8370 - val_accuracy: 0.7500\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 385ms/step - loss: 0.3965 - accuracy: 1.0000 - val_loss: 0.6665 - val_accuracy: 0.5000\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 394ms/step - loss: 0.1933 - accuracy: 1.0000 - val_loss: 0.6287 - val_accuracy: 0.5000\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 0s 390ms/step - loss: 0.1781 - accuracy: 1.0000 - val_loss: 0.6842 - val_accuracy: 0.5000\n",
            "Epoch 10/50\n",
            "1/1 [==============================] - 0s 387ms/step - loss: 0.2192 - accuracy: 1.0000 - val_loss: 0.7069 - val_accuracy: 0.5000\n",
            "Epoch 11/50\n",
            "1/1 [==============================] - 0s 390ms/step - loss: 0.1860 - accuracy: 1.0000 - val_loss: 0.6742 - val_accuracy: 0.5000\n",
            "Epoch 12/50\n",
            "1/1 [==============================] - 0s 386ms/step - loss: 0.1642 - accuracy: 1.0000 - val_loss: 0.6181 - val_accuracy: 0.5000\n",
            "Epoch 13/50\n",
            "1/1 [==============================] - 0s 383ms/step - loss: 0.1222 - accuracy: 1.0000 - val_loss: 0.5876 - val_accuracy: 0.7500\n",
            "Epoch 14/50\n",
            "1/1 [==============================] - 0s 397ms/step - loss: 0.0756 - accuracy: 1.0000 - val_loss: 0.6021 - val_accuracy: 0.7500\n",
            "Epoch 15/50\n",
            "1/1 [==============================] - 0s 393ms/step - loss: 0.0795 - accuracy: 1.0000 - val_loss: 0.6374 - val_accuracy: 0.7500\n",
            "Epoch 16/50\n",
            "1/1 [==============================] - 0s 393ms/step - loss: 0.0713 - accuracy: 1.0000 - val_loss: 0.6650 - val_accuracy: 0.7500\n",
            "Epoch 17/50\n",
            "1/1 [==============================] - 0s 388ms/step - loss: 0.1137 - accuracy: 1.0000 - val_loss: 0.6652 - val_accuracy: 0.7500\n",
            "Epoch 18/50\n",
            "1/1 [==============================] - 0s 391ms/step - loss: 0.0563 - accuracy: 1.0000 - val_loss: 0.6481 - val_accuracy: 0.7500\n",
            "Epoch 19/50\n",
            "1/1 [==============================] - 0s 384ms/step - loss: 0.0715 - accuracy: 1.0000 - val_loss: 0.6170 - val_accuracy: 0.7500\n",
            "Epoch 20/50\n",
            "1/1 [==============================] - 0s 393ms/step - loss: 0.0485 - accuracy: 1.0000 - val_loss: 0.5873 - val_accuracy: 0.5000\n",
            "Epoch 21/50\n",
            "1/1 [==============================] - 0s 394ms/step - loss: 0.0406 - accuracy: 1.0000 - val_loss: 0.5648 - val_accuracy: 0.5000\n",
            "Epoch 22/50\n",
            "1/1 [==============================] - 0s 385ms/step - loss: 0.0220 - accuracy: 1.0000 - val_loss: 0.5549 - val_accuracy: 0.5000\n",
            "Epoch 23/50\n",
            "1/1 [==============================] - 0s 385ms/step - loss: 0.0241 - accuracy: 1.0000 - val_loss: 0.5541 - val_accuracy: 0.5000\n",
            "Epoch 24/50\n",
            "1/1 [==============================] - 0s 384ms/step - loss: 0.0335 - accuracy: 1.0000 - val_loss: 0.5575 - val_accuracy: 0.5000\n",
            "Epoch 25/50\n",
            "1/1 [==============================] - 0s 393ms/step - loss: 0.0238 - accuracy: 1.0000 - val_loss: 0.5619 - val_accuracy: 0.5000\n",
            "Epoch 26/50\n",
            "1/1 [==============================] - 0s 413ms/step - loss: 0.0272 - accuracy: 1.0000 - val_loss: 0.5639 - val_accuracy: 0.5000\n",
            "Epoch 27/50\n",
            "1/1 [==============================] - 0s 394ms/step - loss: 0.0225 - accuracy: 1.0000 - val_loss: 0.5639 - val_accuracy: 0.5000\n",
            "Epoch 28/50\n",
            "1/1 [==============================] - 0s 391ms/step - loss: 0.0342 - accuracy: 1.0000 - val_loss: 0.5592 - val_accuracy: 0.5000\n",
            "Epoch 29/50\n",
            "1/1 [==============================] - 0s 384ms/step - loss: 0.0178 - accuracy: 1.0000 - val_loss: 0.5549 - val_accuracy: 0.7500\n",
            "Epoch 30/50\n",
            "1/1 [==============================] - 0s 389ms/step - loss: 0.0288 - accuracy: 1.0000 - val_loss: 0.5498 - val_accuracy: 0.7500\n",
            "Epoch 31/50\n",
            "1/1 [==============================] - 0s 389ms/step - loss: 0.0118 - accuracy: 1.0000 - val_loss: 0.5466 - val_accuracy: 0.7500\n",
            "Epoch 32/50\n",
            "1/1 [==============================] - 0s 381ms/step - loss: 0.0181 - accuracy: 1.0000 - val_loss: 0.5472 - val_accuracy: 0.7500\n",
            "Epoch 33/50\n",
            "1/1 [==============================] - 0s 383ms/step - loss: 0.0159 - accuracy: 1.0000 - val_loss: 0.5509 - val_accuracy: 0.7500\n",
            "Epoch 34/50\n",
            "1/1 [==============================] - 1s 511ms/step - loss: 0.0137 - accuracy: 1.0000 - val_loss: 0.5578 - val_accuracy: 0.7500\n",
            "Epoch 35/50\n",
            "1/1 [==============================] - 0s 389ms/step - loss: 0.0109 - accuracy: 1.0000 - val_loss: 0.5647 - val_accuracy: 0.7500\n",
            "Epoch 36/50\n",
            "1/1 [==============================] - 0s 402ms/step - loss: 0.0098 - accuracy: 1.0000 - val_loss: 0.5719 - val_accuracy: 0.7500\n",
            "Epoch 37/50\n",
            "1/1 [==============================] - 0s 390ms/step - loss: 0.0121 - accuracy: 1.0000 - val_loss: 0.5782 - val_accuracy: 0.7500\n",
            "Epoch 38/50\n",
            "1/1 [==============================] - 0s 396ms/step - loss: 0.0129 - accuracy: 1.0000 - val_loss: 0.5819 - val_accuracy: 0.7500\n",
            "Epoch 39/50\n",
            "1/1 [==============================] - 0s 404ms/step - loss: 0.0122 - accuracy: 1.0000 - val_loss: 0.5847 - val_accuracy: 0.7500\n",
            "Epoch 40/50\n",
            "1/1 [==============================] - 0s 416ms/step - loss: 0.0109 - accuracy: 1.0000 - val_loss: 0.5856 - val_accuracy: 0.7500\n",
            "Epoch 41/50\n",
            "1/1 [==============================] - 0s 401ms/step - loss: 0.0103 - accuracy: 1.0000 - val_loss: 0.5844 - val_accuracy: 0.7500\n",
            "Epoch 42/50\n",
            "1/1 [==============================] - 0s 393ms/step - loss: 0.0096 - accuracy: 1.0000 - val_loss: 0.5805 - val_accuracy: 0.7500\n",
            "Epoch 43/50\n",
            "1/1 [==============================] - 0s 391ms/step - loss: 0.0103 - accuracy: 1.0000 - val_loss: 0.5753 - val_accuracy: 0.7500\n",
            "Epoch 44/50\n",
            "1/1 [==============================] - 0s 385ms/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 0.5705 - val_accuracy: 0.7500\n",
            "Epoch 45/50\n",
            "1/1 [==============================] - 0s 391ms/step - loss: 0.0110 - accuracy: 1.0000 - val_loss: 0.5644 - val_accuracy: 0.7500\n",
            "Epoch 46/50\n",
            "1/1 [==============================] - 0s 390ms/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 0.5577 - val_accuracy: 0.7500\n",
            "Epoch 47/50\n",
            "1/1 [==============================] - 0s 404ms/step - loss: 0.0096 - accuracy: 1.0000 - val_loss: 0.5499 - val_accuracy: 0.7500\n",
            "Epoch 48/50\n",
            "1/1 [==============================] - 0s 425ms/step - loss: 0.0092 - accuracy: 1.0000 - val_loss: 0.5431 - val_accuracy: 0.7500\n",
            "Epoch 49/50\n",
            "1/1 [==============================] - 0s 391ms/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 0.5377 - val_accuracy: 0.7500\n",
            "Epoch 50/50\n",
            "1/1 [==============================] - 0s 390ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 0.5327 - val_accuracy: 0.7500\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MuT5ooT8EHOs"
      },
      "source": [
        "model.save('model.h5')"
      ],
      "execution_count": 207,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RchXdkgJCyrx",
        "outputId": "e2a0eb8d-cf54-4374-f67a-b5ee9e7fedc5"
      },
      "source": [
        "test_image = image.load_img('/content/catordog.jpg', target_size = (224, 224))\r\n",
        "test_image = image.img_to_array(test_image)\r\n",
        "test_image = np.expand_dims(test_image, axis = 0)\r\n",
        "result = model.predict(test_image)\r\n",
        "\r\n",
        "if result[0][0] == 1:\r\n",
        "  print(\"Prediction: It's a cat's image.\")\r\n",
        "else:\r\n",
        "  print(\"Prediction: It's a dog's image.\")"
      ],
      "execution_count": 208,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Prediction: It's a cat's image.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZCqGyw5ZGQKB",
        "outputId": "47a10b9b-4bf3-48a6-8dcb-f460282cda5c"
      },
      "source": [
        "test_image = image.load_img('/content/catordog1.jpg', target_size = (224, 224))\r\n",
        "test_image = image.img_to_array(test_image)\r\n",
        "test_image = np.expand_dims(test_image, axis = 0)\r\n",
        "result = model.predict(test_image)\r\n",
        "\r\n",
        "if result[0][0] == 1:\r\n",
        "  print(\"Prediction: It's a cat's image.\")\r\n",
        "else:\r\n",
        "  print(\"Prediction: It's a dog's image.\")"
      ],
      "execution_count": 209,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Prediction: It's a cat's image.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Mxf816AG6cF",
        "outputId": "86f158fb-7262-4f9b-b0e2-997f2af12c35"
      },
      "source": [
        "test_image = image.load_img('/content/catordog2.jpg', target_size = (224, 224))\r\n",
        "test_image = image.img_to_array(test_image)\r\n",
        "test_image = np.expand_dims(test_image, axis = 0)\r\n",
        "result = model.predict(test_image)\r\n",
        "\r\n",
        "if result[0][0] == 1:\r\n",
        "  print(\"Prediction: It's a cat's image.\")\r\n",
        "else:\r\n",
        "  print(\"Prediction: It's a dog's image.\")"
      ],
      "execution_count": 210,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Prediction: It's a dog's image.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ugrgBnrGG6pC",
        "outputId": "42b3241e-ffc0-465e-ed42-a55de31429dd"
      },
      "source": [
        "test_image = image.load_img('/content/catordog3.jpg', target_size = (224, 224))\r\n",
        "test_image = image.img_to_array(test_image)\r\n",
        "test_image = np.expand_dims(test_image, axis = 0)\r\n",
        "result = model.predict(test_image)\r\n",
        "\r\n",
        "if result[0][0] == 1:\r\n",
        "  print(\"Prediction: It's a cat's image.\")\r\n",
        "else:\r\n",
        "  print(\"Prediction: It's a dog's image.\")"
      ],
      "execution_count": 211,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Prediction: It's a dog's image.\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}